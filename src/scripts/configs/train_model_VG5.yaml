# Hydra settings
hydra:
  job:
    chdir: false

# Data configuration
data:
  train_file: "data/processed/new/processed_train_VG5.csv"
  eval_file: "data/processed/new/processed_eval_VG5.csv"
  num_operating_modes: 5
  input_feature_cols: [ 'turbine_pressure', 'turbine_rotspeed', 'injector_opening', 'charge', 'coupler_position', 'water_primary_pump_01_opening', 'water_primary_pump_02_opening' ]
  # These are the y_cur columns
  current_value_cols: [
    "air_gap_positive_x_position", "water_circ_flow", "tot_current", "neutral_current",
    "tot_reactivepower", "stat_magn_03_tmp", "air_circ_hot_05_tmp", "stat_coil_ph01_06_tmp",
    "air_circ_cold_05_tmp", "water_circ_hot_03_tmp", "plant_tmp", "ext_tmp",
    "tot_activepower", "stat_coil_ph01_04_tmp"
  ]  # These are the y_next columns
  next_value_cols: [
    "air_gap_positive_x_position", "water_circ_flow", "tot_current", "neutral_current",
    "tot_reactivepower", "stat_magn_03_tmp", "air_circ_hot_05_tmp", "stat_coil_ph01_06_tmp",
    "air_circ_cold_05_tmp", "water_circ_hot_03_tmp", "plant_tmp", "ext_tmp",
    "tot_activepower", "stat_coil_ph01_04_tmp"
  ]
  padding_value: 0.0

# Model configuration
model:
  context_length: 240  # 300 / 2 = 150 minutes
  embedding_dim: 64  #
  state_dim: 256     # Increased state dimension for S5 backbone to handle richer data
  num_s5_layers: 6   # Increased number of S5 layers for more complexity
  s5_dropout: 0.1    # Reduced dropout for S5; too high dropout can impact sequence learning negatively
  fc_hidden_dims: [ 256, 128, 64 ]  # Larger and deeper FC network to process richer sequences
  fc_dropout: 0.1   # Reduced FC dropout to preserve signal for complex sequences

# Training configuration
training:
  batch_size: 64
  learning_rate: 0.0005
  num_gradient_steps: 16_000
  checkpoint_folder: "checkpoints_VG5_bigger"

# Logging configuration
logging:
  use_wandb: true
  project_name: "alpiq_data_challenge"
  run_name: "train_causal_model_VG5_bigger"
